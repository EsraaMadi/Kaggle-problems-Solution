## Titanic: Machine Learning from Disaster

My solution of [Titanic problem](https://www.kaggle.com/c/titanic) on Kaggle.

**Model 1 :
I compared 15 popular classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure:**

1. SVC 
2. LinearSVC
3. Decision Tree
4.  AdaBoost
5. Random Forest
6. Extra Trees
7. Gradient Boosting
8. Multiple layer perceprton (neural network)
9. KNN
10. Logistic regression
11. Linear Discriminant Analysis
12. GaussianNB
13. Perceptron
14. Multiple Layer Perceptron
15. Linear Discriminan tAnalysis

Then I have tunned the best 5 performing models and combined them using a voting classifier to get the final prediction

**Model 2 :
Logistic regression**
(best score)


